# FreshHarvest Training Parameters
# ================================
#
# Comprehensive training configuration for the FreshHarvest
# fruit freshness classification model.
#
# Author: FreshHarvest Team
# Version: 1.0.0
# Target Accuracy: 96.50%

# Training Configuration
training:
  # Basic training settings
  epochs: 50
  batch_size: 32
  validation_split: 0.2
  test_split: 0.1

  # Learning rate configuration
  initial_learning_rate: 0.001
  learning_rate_decay: 0.95
  decay_steps: 1000

  # Optimizer settings
  optimizer:
    type: "Adam"
    learning_rate: 0.001
    beta_1: 0.9
    beta_2: 0.999
    epsilon: 1e-07
    amsgrad: false

  # Loss function
  loss_function: "categorical_crossentropy"

  # Metrics to track during training
  metrics:
    - "accuracy"
    - "precision"
    - "recall"
    - "f1_score"
    - "top_2_accuracy"

# Early Stopping Configuration
early_stopping:
  # Monitoring settings
  monitor: "val_accuracy"
  patience: 10
  min_delta: 0.001
  mode: "max"
  restore_best_weights: true
  verbose: 1

  # Baseline settings
  baseline: 0.95  # Stop if validation accuracy reaches 95%
  start_from_epoch: 5  # Start monitoring after epoch 5

# Learning Rate Scheduling
lr_scheduler:
  # Primary scheduler
  type: "ReduceLROnPlateau"
  monitor: "val_loss"
  factor: 0.5
  patience: 5
  min_lr: 1e-07
  verbose: 1
  cooldown: 2

  # Alternative schedulers (commented out)
  # exponential_decay:
  #   initial_learning_rate: 0.001
  #   decay_steps: 1000
  #   decay_rate: 0.96
  #   staircase: true

  # cosine_decay:
  #   initial_learning_rate: 0.001
  #   decay_steps: 10000
  #   alpha: 0.0

# Model Checkpointing
model_checkpoint:
  # Checkpoint settings
  filepath: "artifacts/model_trainer/checkpoints/model_epoch_{epoch:02d}_acc_{val_accuracy:.4f}.h5"
  monitor: "val_accuracy"
  save_best_only: true
  save_weights_only: false
  mode: "max"
  verbose: 1
  save_freq: "epoch"

  # Backup settings
  backup_and_restore: true
  max_to_keep: 5

# Data Augmentation
data_augmentation:
  # Basic augmentations
  rotation_range: 20
  width_shift_range: 0.1
  height_shift_range: 0.1
  shear_range: 0.1
  zoom_range: 0.1
  horizontal_flip: true
  vertical_flip: false
  fill_mode: "nearest"

  # Color augmentations
  brightness_range: [0.8, 1.2]
  channel_shift_range: 0.1

  # Normalization
  rescale: 0.00392156862745098  # 1/255
  featurewise_center: false
  samplewise_center: false
  featurewise_std_normalization: false
  samplewise_std_normalization: false

  # Advanced augmentations
  cutout:
    enabled: false
    mask_size: 16
    probability: 0.5

  mixup:
    enabled: false
    alpha: 0.2

  cutmix:
    enabled: false
    alpha: 1.0

# Transfer Learning Configuration
transfer_learning:
  # Pre-trained model settings
  base_model: "EfficientNetB0"
  weights: "imagenet"
  include_top: false
  pooling: "avg"

  # Fine-tuning strategy
  freeze_base_model: true
  unfreeze_after_epoch: 20
  unfreeze_layers: 50  # Number of layers to unfreeze

  # Fine-tuning learning rate
  fine_tune_learning_rate: 0.0001

# Class Balancing
class_balancing:
  # Class weights for imbalanced data
  use_class_weights: true
  class_weights:
    0: 1.0  # Fresh Apple
    1: 1.0  # Fresh Banana
    2: 1.0  # Fresh Orange
    3: 1.1  # Rotten Apple
    4: 1.1  # Rotten Banana
    5: 1.1  # Rotten Orange

  # Sampling strategies
  oversampling:
    enabled: false
    method: "SMOTE"

  undersampling:
    enabled: false
    method: "RandomUnderSampler"

# Regularization Techniques
regularization:
  # Dropout settings
  dropout_rate: 0.3
  spatial_dropout_rate: 0.2

  # L1/L2 regularization
  l1_regularization: 0.0
  l2_regularization: 0.001

  # Batch normalization
  batch_normalization: true

  # Label smoothing
  label_smoothing: 0.1

# Training Monitoring
monitoring:
  # TensorBoard logging
  tensorboard:
    enabled: true
    log_dir: "logs/tensorboard"
    histogram_freq: 1
    write_graph: true
    write_images: true
    update_freq: "epoch"

  # MLflow tracking
  mlflow:
    enabled: true
    experiment_name: "FreshHarvest_Training"
    run_name: "EfficientNetB0_96.5_accuracy"
    tracking_uri: "file:./mlruns"

  # Custom callbacks
  custom_callbacks:
    - "LearningRateLogger"
    - "MemoryUsageLogger"
    - "TrainingTimeLogger"

# Validation Strategy
validation:
  # Validation data configuration
  validation_split: 0.2
  shuffle: true
  stratify: true

  # Cross-validation settings
  cross_validation:
    enabled: false
    folds: 5
    stratified: true
    shuffle: true
    random_state: 42

  # Validation frequency
  validation_freq: 1  # Validate every epoch
  validation_steps: null  # Use all validation data

# Performance Optimization
performance:
  # Mixed precision training
  mixed_precision:
    enabled: false
    policy: "mixed_float16"

  # Multi-GPU training
  multi_gpu:
    enabled: false
    strategy: "MirroredStrategy"

  # Memory optimization
  memory_optimization:
    gradient_checkpointing: false
    memory_growth: true

  # Data pipeline optimization
  data_pipeline:
    prefetch_buffer_size: 2
    num_parallel_calls: 4
    cache_dataset: false

# Training Targets and Thresholds
targets:
  # Accuracy targets
  target_accuracy: 0.965        # 96.50% validation accuracy
  minimum_accuracy: 0.95        # Minimum acceptable accuracy
  training_accuracy: 0.98       # Target training accuracy

  # Loss targets
  target_loss: 0.15             # Target validation loss
  maximum_loss: 0.25            # Maximum acceptable loss

  # Training time limits
  max_training_time_hours: 6    # Maximum training time
  max_epochs_without_improvement: 15

  # Resource limits
  max_memory_usage_gb: 8        # Maximum memory usage
  max_gpu_memory_gb: 6          # Maximum GPU memory

# Experiment Configuration
experiment:
  # Experiment metadata
  name: "FreshHarvest_Training_v1.0"
  description: "Training EfficientNetB0 for 96.50% accuracy"
  tags:
    - "fruit_classification"
    - "freshness_detection"
    - "efficientnet"
    - "96.5_accuracy"

  # Reproducibility
  random_seed: 42
  deterministic: true

  # Logging
  log_level: "INFO"
  save_logs: true
  log_file: "logs/training.log"

# Hardware Configuration
hardware:
  # GPU settings
  gpu:
    enabled: true
    memory_growth: true
    allow_memory_growth: true
    per_process_gpu_memory_fraction: 0.8

  # CPU settings
  cpu:
    threads: 4
    inter_op_parallelism_threads: 0
    intra_op_parallelism_threads: 0

  # Memory settings
  memory:
    limit_gb: 8
    swap_enabled: false

# Data Configuration
data:
  # Data paths
  train_data_path: "data/processed/train"
  validation_data_path: "data/processed/validation"
  test_data_path: "data/processed/test"

  # Image preprocessing
  image_size: [224, 224]
  channels: 3
  color_mode: "rgb"

  # Data loading
  shuffle_buffer_size: 1000
  prefetch_buffer_size: 2
  num_parallel_calls: 4

  # Data validation
  validate_data: true
  check_image_integrity: true
  remove_corrupted_images: true

# Model Architecture Specific
architecture:
  # EfficientNet specific settings
  efficientnet:
    model_name: "EfficientNetB0"
    input_shape: [224, 224, 3]
    include_top: false
    weights: "imagenet"
    pooling: "avg"

    # Custom head
    dense_units: 512
    dropout_rate: 0.3
    activation: "relu"
    final_activation: "softmax"

    # Batch normalization
    use_batch_norm: true
    batch_norm_momentum: 0.99
    batch_norm_epsilon: 0.001

# Post-training Configuration
post_training:
  # Model evaluation
  evaluate_on_test: true
  generate_classification_report: true
  save_confusion_matrix: true

  # Model optimization
  quantization:
    enabled: false
    type: "dynamic"

  # Model conversion
  convert_to_tflite: false
  convert_to_onnx: false

  # Model validation
  validate_converted_models: true
  accuracy_tolerance: 0.01