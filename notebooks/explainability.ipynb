{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FreshHarvest Model Explainability\n",
    "\n",
    "This notebook provides explainability analysis for FreshHarvest models using various interpretation techniques.\n",
    "\n",
    "## Explainability Overview\n",
    "- Grad-CAM visualizations\n",
    "- Feature importance analysis\n",
    "- Layer activation visualizations\n",
    "- Model decision interpretation\n",
    "- Prediction confidence analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Import custom modules\n",
    "from cvProject_FreshHarvest.utils.common import read_yaml, setup_logging\n",
    "\n",
    "# Setup\n",
    "setup_logging()\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"FreshHarvest Model Explainability Notebook\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model and Configuration Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = read_yaml('../config/config.yaml')\n",
    "CLASS_NAMES = [\n",
    "    'F_Banana', 'F_Lemon', 'F_Lulo', 'F_Mango', 'F_Orange', 'F_Strawberry', 'F_Tamarillo', 'F_Tomato',\n",
    "    'S_Banana', 'S_Lemon', 'S_Lulo', 'S_Mango', 'S_Orange', 'S_Strawberry', 'S_Tamarillo', 'S_Tomato'\n",
    "]\n",
    "\n",
    "# Load trained model\n",
    "model_paths = [\n",
    "    '../models/trained/best_model.h5',\n",
    "    '../models/checkpoints/best_model_20250618_100126.h5'\n",
    "]\n",
    "\n",
    "model = None\n",
    "for path in model_paths:\n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            model = keras.models.load_model(path)\n",
    "            print(f\"✅ Model loaded from: {path}\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to load {path}: {e}\")\n",
    "\n",
    "if model is None:\n",
    "    print(\"⚠️ No model found. Creating dummy model for demonstration.\")\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input(shape=(224, 224, 3)),\n",
    "        keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.Dense(16, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Grad-CAM Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    \"\"\"Generate Grad-CAM heatmap.\"\"\"\n",
    "    \n",
    "    # Create gradient model\n",
    "    grad_model = keras.models.Model(\n",
    "        inputs=[model.inputs],\n",
    "        outputs=[model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "    \n",
    "    # Compute gradients\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "    \n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    \n",
    "    # Generate heatmap\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    \n",
    "    return heatmap.numpy()\n",
    "\n",
    "def find_last_conv_layer(model):\n",
    "    \"\"\"Find the last convolutional layer.\"\"\"\n",
    "    for layer in reversed(model.layers):\n",
    "        if 'conv' in layer.name.lower():\n",
    "            return layer.name\n",
    "    return None\n",
    "\n",
    "# Find last conv layer\n",
    "last_conv_layer = find_last_conv_layer(model)\n",
    "print(f\"Last conv layer: {last_conv_layer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sample Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample images for analysis\n",
    "def load_sample_image(image_path, target_size=(224, 224)):\n",
    "    \"\"\"Load and preprocess a sample image.\"\"\"\n",
    "    try:\n",
    "        img = load_img(image_path, target_size=target_size)\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = img_array / 255.0\n",
    "        return img_array, img\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image: {e}\")\n",
    "        # Create dummy image\n",
    "        img_array = np.random.random((1, 224, 224, 3))\n",
    "        img = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)\n",
    "        return img_array, img\n",
    "\n",
    "# Try to find sample images\n",
    "sample_paths = []\n",
    "data_dirs = ['../data/processed/test', '../data/processed/val']\n",
    "\n",
    "for data_dir in data_dirs:\n",
    "    if os.path.exists(data_dir):\n",
    "        for class_name in CLASS_NAMES[:4]:  # First 4 classes\n",
    "            class_dir = os.path.join(data_dir, class_name)\n",
    "            if os.path.exists(class_dir):\n",
    "                images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "                if images:\n",
    "                    sample_paths.append((os.path.join(class_dir, images[0]), class_name))\n",
    "                    break\n",
    "        if sample_paths:\n",
    "            break\n",
    "\n",
    "if not sample_paths:\n",
    "    print(\"⚠️ No sample images found. Using dummy data.\")\n",
    "    sample_paths = [('dummy.jpg', 'F_Banana')]\n",
    "\n",
    "print(f\"Found {len(sample_paths)} sample images for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Grad-CAM Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Grad-CAM visualizations\n",
    "def visualize_gradcam(img_path, class_name, model, last_conv_layer):\n",
    "    \"\"\"Create Grad-CAM visualization.\"\"\"\n",
    "    \n",
    "    # Load image\n",
    "    img_array, original_img = load_sample_image(img_path)\n",
    "    \n",
    "    # Make prediction\n",
    "    preds = model.predict(img_array, verbose=0)\n",
    "    predicted_class = np.argmax(preds[0])\n",
    "    confidence = preds[0][predicted_class]\n",
    "    \n",
    "    print(f\"\\nAnalyzing: {class_name}\")\n",
    "    print(f\"Predicted: {CLASS_NAMES[predicted_class]} (confidence: {confidence:.3f})\")\n",
    "    \n",
    "    if last_conv_layer:\n",
    "        # Generate Grad-CAM\n",
    "        try:\n",
    "            heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer, predicted_class)\n",
    "            \n",
    "            # Create visualization\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "            \n",
    "            # Original image\n",
    "            if isinstance(original_img, np.ndarray):\n",
    "                axes[0].imshow(original_img)\n",
    "            else:\n",
    "                axes[0].imshow(original_img)\n",
    "            axes[0].set_title(f'Original\\n{class_name}')\n",
    "            axes[0].axis('off')\n",
    "            \n",
    "            # Heatmap\n",
    "            axes[1].imshow(heatmap, cmap='jet')\n",
    "            axes[1].set_title('Grad-CAM Heatmap')\n",
    "            axes[1].axis('off')\n",
    "            \n",
    "            # Overlay\n",
    "            if isinstance(original_img, np.ndarray):\n",
    "                overlay_img = original_img\n",
    "            else:\n",
    "                overlay_img = np.array(original_img)\n",
    "            \n",
    "            heatmap_resized = cv2.resize(heatmap, (224, 224))\n",
    "            heatmap_colored = plt.cm.jet(heatmap_resized)[:, :, :3]\n",
    "            overlay = 0.6 * overlay_img/255.0 + 0.4 * heatmap_colored\n",
    "            \n",
    "            axes[2].imshow(overlay)\n",
    "            axes[2].set_title(f'Overlay\\nPred: {CLASS_NAMES[predicted_class][:8]}... ({confidence:.3f})')\n",
    "            axes[2].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating Grad-CAM: {e}\")\n",
    "    else:\n",
    "        print(\"No convolutional layer found for Grad-CAM\")\n",
    "\n",
    "# Generate visualizations for sample images\n",
    "for img_path, class_name in sample_paths[:3]:  # Analyze first 3 samples\n",
    "    visualize_gradcam(img_path, class_name, model, last_conv_layer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}