{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FreshHarvest Data Analysis\n",
    "\n",
    "This notebook provides comprehensive data analysis for the FreshHarvest fruit freshness classification dataset.\n",
    "\n",
    "## Analysis Overview\n",
    "- Dataset structure and statistics\n",
    "- Class distribution analysis\n",
    "- Image quality assessment\n",
    "- Data preprocessing insights\n",
    "- Visualization of sample images\n",
    "- Data quality recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "from cvProject_FreshHarvest.utils.common import read_yaml, setup_logging\n",
    "\n",
    "# Setup\n",
    "setup_logging()\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"FreshHarvest Data Analysis Notebook\")\n",
    "print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = read_yaml('../config/config.yaml')\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"- Image size: {config['data']['image_size']}\")\n",
    "print(f\"- Number of classes: {config['data']['num_classes']}\")\n",
    "print(f\"- Batch size: {config['training']['batch_size']}\")\n",
    "\n",
    "# Define paths\n",
    "data_paths = {\n",
    "    'raw': '../data/raw',\n",
    "    'processed': '../data/processed',\n",
    "    'train': '../data/processed/train',\n",
    "    'val': '../data/processed/val',\n",
    "    'test': '../data/processed/test'\n",
    "}\n",
    "\n",
    "# Class names\n",
    "CLASS_NAMES = [\n",
    "    'F_Banana', 'F_Lemon', 'F_Lulo', 'F_Mango', 'F_Orange', 'F_Strawberry', 'F_Tamarillo', 'F_Tomato',\n",
    "    'S_Banana', 'S_Lemon', 'S_Lulo', 'S_Mango', 'S_Orange', 'S_Strawberry', 'S_Tamarillo', 'S_Tomato'\n",
    "]\n",
    "\n",
    "print(f\"\\nClass names: {CLASS_NAMES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Structure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset_structure(data_path):\n",
    "    \"\"\"Analyze the structure of the dataset.\"\"\"\n",
    "    \n",
    "    if not os.path.exists(data_path):\n",
    "        print(f\"âš ï¸ Path does not exist: {data_path}\")\n",
    "        return None\n",
    "    \n",
    "    structure = {}\n",
    "    total_images = 0\n",
    "    \n",
    "    print(f\"\\nðŸ“ Analyzing: {data_path}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for class_name in os.listdir(data_path):\n",
    "        class_path = os.path.join(data_path, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            # Count images in class directory\n",
    "            image_files = [f for f in os.listdir(class_path) \n",
    "                          if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "            count = len(image_files)\n",
    "            structure[class_name] = count\n",
    "            total_images += count\n",
    "            \n",
    "            print(f\"{class_name:15}: {count:5d} images\")\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'Total':15}: {total_images:5d} images\")\n",
    "    \n",
    "    return structure\n",
    "\n",
    "# Analyze each dataset split\n",
    "dataset_structures = {}\n",
    "for split_name, split_path in data_paths.items():\n",
    "    if split_name in ['train', 'val', 'test']:\n",
    "        dataset_structures[split_name] = analyze_dataset_structure(split_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Class Distribution Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class distribution visualization\n",
    "def plot_class_distribution(dataset_structures):\n",
    "    \"\"\"Plot class distribution across dataset splits.\"\"\"\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    plot_data = []\n",
    "    \n",
    "    for split_name, structure in dataset_structures.items():\n",
    "        if structure:\n",
    "            for class_name, count in structure.items():\n",
    "                plot_data.append({\n",
    "                    'Split': split_name,\n",
    "                    'Class': class_name,\n",
    "                    'Count': count,\n",
    "                    'Fruit': class_name.split('_')[1] if '_' in class_name else class_name,\n",
    "                    'Condition': 'Fresh' if class_name.startswith('F_') else 'Spoiled'\n",
    "                })\n",
    "    \n",
    "    if not plot_data:\n",
    "        print(\"âš ï¸ No data available for plotting\")\n",
    "        return\n",
    "    \n",
    "    df = pd.DataFrame(plot_data)\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Class distribution by split\n",
    "    df_pivot = df.pivot_table(index='Class', columns='Split', values='Count', fill_value=0)\n",
    "    df_pivot.plot(kind='bar', ax=axes[0, 0], width=0.8)\n",
    "    axes[0, 0].set_title('Class Distribution by Dataset Split')\n",
    "    axes[0, 0].set_xlabel('Class')\n",
    "    axes[0, 0].set_ylabel('Number of Images')\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # 2. Fresh vs Spoiled distribution\n",
    "    condition_counts = df.groupby(['Split', 'Condition'])['Count'].sum().reset_index()\n",
    "    condition_pivot = condition_counts.pivot(index='Split', columns='Condition', values='Count')\n",
    "    condition_pivot.plot(kind='bar', ax=axes[0, 1], width=0.6)\n",
    "    axes[0, 1].set_title('Fresh vs Spoiled Distribution')\n",
    "    axes[0, 1].set_xlabel('Dataset Split')\n",
    "    axes[0, 1].set_ylabel('Number of Images')\n",
    "    axes[0, 1].tick_params(axis='x', rotation=0)\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # 3. Fruit type distribution\n",
    "    fruit_counts = df.groupby(['Split', 'Fruit'])['Count'].sum().reset_index()\n",
    "    fruit_pivot = fruit_counts.pivot(index='Fruit', columns='Split', values='Count')\n",
    "    fruit_pivot.plot(kind='bar', ax=axes[1, 0], width=0.8)\n",
    "    axes[1, 0].set_title('Distribution by Fruit Type')\n",
    "    axes[1, 0].set_xlabel('Fruit Type')\n",
    "    axes[1, 0].set_ylabel('Number of Images')\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # 4. Total dataset composition\n",
    "    total_by_split = df.groupby('Split')['Count'].sum()\n",
    "    axes[1, 1].pie(total_by_split.values, labels=total_by_split.index, autopct='%1.1f%%')\n",
    "    axes[1, 1].set_title('Dataset Split Composition')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Plot class distribution\n",
    "df_analysis = plot_class_distribution(dataset_structures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Image Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_quality(data_path, sample_size=100):\n",
    "    \"\"\"Analyze image quality metrics.\"\"\"\n",
    "    \n",
    "    if not os.path.exists(data_path):\n",
    "        print(f\"âš ï¸ Path does not exist: {data_path}\")\n",
    "        return None\n",
    "    \n",
    "    quality_metrics = {\n",
    "        'widths': [],\n",
    "        'heights': [],\n",
    "        'channels': [],\n",
    "        'file_sizes': [],\n",
    "        'brightness': [],\n",
    "        'contrast': []\n",
    "    }\n",
    "    \n",
    "    sample_count = 0\n",
    "    \n",
    "    print(f\"\\nðŸ” Analyzing image quality from: {data_path}\")\n",
    "    print(f\"Sample size: {sample_size} images\")\n",
    "    \n",
    "    for class_name in os.listdir(data_path):\n",
    "        class_path = os.path.join(data_path, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            image_files = [f for f in os.listdir(class_path) \n",
    "                          if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "            \n",
    "            # Sample images from this class\n",
    "            class_sample_size = min(sample_size // 16, len(image_files))  # Distribute across classes\n",
    "            sampled_files = np.random.choice(image_files, class_sample_size, replace=False)\n",
    "            \n",
    "            for img_file in sampled_files:\n",
    "                if sample_count >= sample_size:\n",
    "                    break\n",
    "                    \n",
    "                img_path = os.path.join(class_path, img_file)\n",
    "                \n",
    "                try:\n",
    "                    # Load image\n",
    "                    img = cv2.imread(img_path)\n",
    "                    if img is not None:\n",
    "                        height, width, channels = img.shape\n",
    "                        \n",
    "                        # Basic metrics\n",
    "                        quality_metrics['widths'].append(width)\n",
    "                        quality_metrics['heights'].append(height)\n",
    "                        quality_metrics['channels'].append(channels)\n",
    "                        quality_metrics['file_sizes'].append(os.path.getsize(img_path))\n",
    "                        \n",
    "                        # Convert to grayscale for brightness/contrast analysis\n",
    "                        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                        quality_metrics['brightness'].append(np.mean(gray))\n",
    "                        quality_metrics['contrast'].append(np.std(gray))\n",
    "                        \n",
    "                        sample_count += 1\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {img_path}: {e}\")\n",
    "                    continue\n",
    "    \n",
    "    print(f\"âœ… Analyzed {sample_count} images\")\n",
    "    return quality_metrics\n",
    "\n",
    "# Analyze image quality for training set\n",
    "train_quality = analyze_image_quality(data_paths['train'], sample_size=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}