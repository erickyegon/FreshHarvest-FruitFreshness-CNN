{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FreshHarvest Model Explainability Analysis\n",
    "\n",
    "This notebook provides explainability analysis for the FreshHarvest fruit freshness classification model including:\n",
    "- Grad-CAM visualizations\n",
    "- Feature importance analysis\n",
    "- Layer activation visualizations\n",
    "- Model interpretation techniques\n",
    "- Decision boundary analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "# Import custom modules\n",
    "from cvProject_FreshHarvest.utils.common import read_yaml, setup_logging\n",
    "from cvProject_FreshHarvest.models.cnn_models import FreshHarvestCNN\n",
    "\n",
    "# Setup\n",
    "setup_logging()\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Model and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = read_yaml('../config/config.yaml')\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"- Image size: {config['data']['image_size']}\")\n",
    "print(f\"- Number of classes: {config['data']['num_classes']}\")\n",
    "\n",
    "# Define class names\n",
    "CLASS_NAMES = [\n",
    "    'F_Banana', 'F_Lemon', 'F_Lulo', 'F_Mango', 'F_Orange', 'F_Strawberry', 'F_Tamarillo', 'F_Tomato',\n",
    "    'S_Banana', 'S_Lemon', 'S_Lulo', 'S_Mango', 'S_Orange', 'S_Strawberry', 'S_Tamarillo', 'S_Tomato'\n",
    "]\n",
    "\n",
    "print(f\"\\nClass names: {CLASS_NAMES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "def load_trained_model(model_path):\n",
    "    \"\"\"Load a trained model from file.\"\"\"\n",
    "    try:\n",
    "        model = keras.models.load_model(model_path)\n",
    "        print(f\"‚úÖ Model loaded successfully from {model_path}\")\n",
    "        print(f\"Model input shape: {model.input_shape}\")\n",
    "        print(f\"Model output shape: {model.output_shape}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load model: {e}\")\n",
    "        return None\n",
    "\n",
    "# Try to load different model files\n",
    "model_paths = [\n",
    "    '../models/trained/best_model.h5',\n",
    "    '../models/best_hypertuned_model.h5',\n",
    "    '../models/checkpoints/best_model_20250618_100126.h5'\n",
    "]\n",
    "\n",
    "model = None\n",
    "for path in model_paths:\n",
    "    if os.path.exists(path):\n",
    "        model = load_trained_model(path)\n",
    "        if model is not None:\n",
    "            print(f\"Using model: {path}\")\n",
    "            break\n",
    "\n",
    "if model is None:\n",
    "    print(\"‚ö†Ô∏è No trained model found. Creating a new lightweight model for demonstration.\")\n",
    "    cnn_builder = FreshHarvestCNN('../config/config.yaml')\n",
    "    model = cnn_builder.create_lightweight_cnn()\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "# Display model architecture\n",
    "print(\"\\nüìã Model Architecture Summary:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Grad-CAM Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grad-CAM implementation\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    \"\"\"Generate Grad-CAM heatmap.\"\"\"\n",
    "    \n",
    "    # Create a model that maps the input image to the activations of the last conv layer\n",
    "    # as well as the output predictions\n",
    "    grad_model = keras.models.Model(\n",
    "        inputs=[model.inputs],\n",
    "        outputs=[model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "    \n",
    "    # Compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "    \n",
    "    # Gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "    \n",
    "    # Vector of mean intensity of the gradient over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    \n",
    "    # Multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    \n",
    "    # Normalize the heatmap between 0 & 1 for visualization\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "def find_last_conv_layer(model):\n",
    "    \"\"\"Find the last convolutional layer in the model.\"\"\"\n",
    "    for layer in reversed(model.layers):\n",
    "        if 'conv' in layer.name.lower():\n",
    "            return layer.name\n",
    "    return None\n",
    "\n",
    "# Find the last convolutional layer\n",
    "last_conv_layer_name = find_last_conv_layer(model)\n",
    "print(f\"Last convolutional layer: {last_conv_layer_name}\")\n",
    "\n",
    "if last_conv_layer_name is None:\n",
    "    print(\"‚ö†Ô∏è No convolutional layer found in the model\")\n",
    "else:\n",
    "    print(f\"‚úÖ Using layer '{last_conv_layer_name}' for Grad-CAM analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Sample Images for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample images for explainability analysis\n",
    "def load_sample_images(data_dir, num_samples=5):\n",
    "    \"\"\"Load sample images from each class.\"\"\"\n",
    "    \n",
    "    sample_images = []\n",
    "    sample_labels = []\n",
    "    sample_paths = []\n",
    "    \n",
    "    try:\n",
    "        for class_idx, class_name in enumerate(CLASS_NAMES[:8]):  # First 8 classes\n",
    "            class_dir = os.path.join(data_dir, class_name)\n",
    "            if os.path.exists(class_dir):\n",
    "                image_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "                \n",
    "                # Take first available image\n",
    "                if image_files:\n",
    "                    img_path = os.path.join(class_dir, image_files[0])\n",
    "                    \n",
    "                    # Load and preprocess image\n",
    "                    img = load_img(img_path, target_size=tuple(config['data']['image_size']))\n",
    "                    img_array = img_to_array(img)\n",
    "                    img_array = np.expand_dims(img_array, axis=0)\n",
    "                    img_array = img_array / 255.0  # Normalize\n",
    "                    \n",
    "                    sample_images.append(img_array)\n",
    "                    sample_labels.append(class_idx)\n",
    "                    sample_paths.append(img_path)\n",
    "                    \n",
    "                    print(f\"‚úÖ Loaded sample for {class_name}\")\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è No images found for {class_name}\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Directory not found: {class_dir}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading sample images: {e}\")\n",
    "        # Create dummy data for demonstration\n",
    "        print(\"Creating dummy sample images for demonstration...\")\n",
    "        for i in range(4):\n",
    "            dummy_img = np.random.random((1, 224, 224, 3))\n",
    "            sample_images.append(dummy_img)\n",
    "            sample_labels.append(i)\n",
    "            sample_paths.append(f\"dummy_image_{i}.jpg\")\n",
    "    \n",
    "    return sample_images, sample_labels, sample_paths\n",
    "\n",
    "# Load sample images\n",
    "sample_dirs = ['../data/processed/test', '../data/processed/val', '../data/raw']\n",
    "sample_images, sample_labels, sample_paths = None, None, None\n",
    "\n",
    "for data_dir in sample_dirs:\n",
    "    if os.path.exists(data_dir):\n",
    "        print(f\"\\nTrying to load samples from: {data_dir}\")\n",
    "        sample_images, sample_labels, sample_paths = load_sample_images(data_dir)\n",
    "        if sample_images:\n",
    "            break\n",
    "\n",
    "if not sample_images:\n",
    "    print(\"\\n‚ö†Ô∏è No sample images found. Creating dummy data for demonstration.\")\n",
    "    sample_images = [np.random.random((1, 224, 224, 3)) for _ in range(4)]\n",
    "    sample_labels = [0, 1, 2, 3]\n",
    "    sample_paths = [f\"dummy_image_{i}.jpg\" for i in range(4)]\n",
    "\n",
    "print(f\"\\n‚úÖ Loaded {len(sample_images)} sample images for analysis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}